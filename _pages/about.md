---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!---
<p align="center">
  <img src="https://github.com/peterbhase/peterbhase.github.io/blob/master/images/s2.jpg?raw=True" alt="Photo" style="width: 300px;"/> 
</p>
-->

## About Me

I am software engineer in Google Cloud AI working on improving text generation quality with Gemini. I obtained my PhD degree from Duke University in 2023, advised by Professor [Ricardo Henao](https://ece.duke.edu/faculty/ricardo-henao). My PhD research lies in the area of low-resource training with pretrained deep learning models, for the tasks of text generation, text/image retrieval, natural language understanding, medical data analysis, etc. Previously, I interned in Adobe (2023) working on mitigating hallucination in text generation with large language models. I also interned in Adobe (2021) on continual few-shot learning and Amazon (2020) on knowledge distillation.



## News
* 2024 - Joining Google Cloud AI working on Gemini
* 2023 - Review for ARR, EMNLP, BMCV, AISTATS, SIGIR, UAI and AAAI
* 2023 - Research Intern in Adobe Research on mitigating hallucination in text generation
* 2023 - One Paper accepted by NeurIps
* 2023 - One paper accepted by Findings of ACL
* 2023 - Invited talk in Fidelity Investments on "Efficient Low-Resource Training with Pretrained Language Models"
* 2023 - One paper accepted by AAAI
* 2023 - One paper accepted by AISTATS
* 2022 - Review for AAAI, ARR, BMVC
* 2022 - Research Intern at Adobe Research
* 2022 - One paper accepted by Findings of EMNLP
* 2022 - One paper accepted by ACL
* 2021 - Review for AAAI
* 2021 - One paper accepted by EMNLP
* 2020 - Applied Scientist Intern at Amazon Alexa
* 2020 - One paper accepted by Findings of EMNLP

## Selceted Publications

1. Huang C*, **Wang R\***, et al. "Model-Aware Retrieval Augmentation with Large Language Models." (Submitted to ACL Rolling Review)
  
2. **Wang R**, et al. "Gradient-Free Personalized Federated Learning with Pretrained Language Models." (Submitted to ACL Rolling Review)

3. Wu J, Yu T, **Wang R**, Song Z, Zhang R, Zhao H, Lu C, Li S, Henao R. "InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding" (NeurIps 2023)

4. **Wang R**, Yu T, Wu J, Zhao H, Kim S, Zhang R, Mitra S, Henao R. "Federated Domain Adaptation for Named Entity Recognition via Distilling with Heterogeneous Tag Sets." (Finds of ACL 2023)

5. Wu J\*, **Wang R\***, Zhao H, Zhang R, Lu C, Li S, Henao R. "[Few-Shot Composition Learning for Image Retrieval with Prompt Tuning.](https://github.com/RayWangWR/Compositional-Image-Retrieval)" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 4. 2023.

6. **Wang R**, Cheng P, Henao R. "[Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling.](https://github.com/RayWangWR/Fair-Text-Generation)" International Conference on Artificial Intelligence and Statistics (AISTATS). PMLR, 2023.

7. Wu J*, **Wang R\***, Yu T, Zhang R, Zhao H, Li S, Henao R, Nenkova A. "[Context-aware Information-theoretic Causal De-biasing for Interactive Sequence Labeling.](https://aclanthology.org/2022.findings-emnlp.251.pdf)" Findings of the Association for Computational Linguistics: EMNLP 2022.

8. **Wang R**, Yu T, Zhao H, Kim S, Mitra S, Zhang R, Henao R.  "[Few-Shot Class-Incremental Learning for Named Entity Recognition.](https://aclanthology.org/2022.acl-long.43/)" Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL). 2022.

9. **Wang R**, Henao R. "[Wasserstein Cross-Lingual Alignment for Named Entity Recognition.](https://ieeexplore.ieee.org/abstract/document/9746120)" ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022.

10. **Wang R**, Henao R. "[Unsupervised Paraphrasing Consistency Training for Low Resource Named Entity Recognition.](https://aclanthology.org/2021.emnlp-main.430/)" Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2021.

11. Dov D, Assaad S, Si S, **Wang R**, Xu H, Kovalsky SZ, Bell J, Range DE, Cohen J, Henao R, Carin L. "[Affinitention Nets: Kernel Perspective on Attention Architectures for Set Classification with Applications to Medical Text and Images.](https://dl.acm.org/doi/abs/10.1145/3450439.3451856)" Proceedings of the Conference on Health, Inference, and Learning. 2021.

12. **Wang R**, Si S, Wang G, Zhang L, Carin L, Henao R. "[Integrating Task Specific Information into Pretrained Language Models for Low Resource Fine Tuning.](https://github.com/RayWangWR/BERT_label_embedding)" Findings of the Association for Computational Linguistics: EMNLP 2020.

13. Si S, **Wang R**, Wosik J, Zhang H, Dov D, Wang G, Carin L. "[Students Need More Attention: Bert-Based Attention Model for Small Data with Application to Automatic Patient Message Triage.](http://proceedings.mlr.press/v126/si20a.html)" Machine Learning for Healthcare Conference. PMLR, 2020.

14. **Wang R**, Wang G, Henao R. "[Discriminative Clustering for Robust Unsupervised Domain Adaptation.](https://arxiv.org/abs/1905.13331)" arXiv preprint arXiv:1905.13331 (2019).



